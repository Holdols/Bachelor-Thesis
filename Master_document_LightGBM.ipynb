{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from mccv import MonteCarloCV\n",
    "\n",
    "from functions_new import get_train_test\n",
    "from functions_new import rolling_window_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LÃ¦s data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/training_data.csv\", sep = \";\")\n",
    "df = pd.get_dummies(df, columns=['HourCET'], prefix='Hour')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LightGBM_all(search, df_train, df_test, train_size, path, get_counts = True, hyp_opt_freq=60):\n",
    "    wind_col = [p for p in df.columns.values if \"wind\" in p]\n",
    "    solar_col = [p for p in df.columns.values if \"solar\" in p]\n",
    "    temp_col = [p for p in df.columns.values if \"temp\" in p]\n",
    "    load_col = [p for p in df.columns.values if \"load\" in p and '_h' in p]\n",
    "    weekday = ['Mon', 'Tue', 'Wen', 'Thur', 'Fri', 'Sat', 'Sun']\n",
    "    windprod_col = [p for p in df.columns.values if \"Wind\" in p in p and '_h' in p]\n",
    "    price_col = [p for p in df.columns.values if \"Price\" in p and p != 'PriceMWh' and '_h' in p]\n",
    "    min_col = [p for p in df.columns.values if \"Min\" in p]\n",
    "    max_col = [p for p in df.columns.values if \"Max\" in p]\n",
    "    avg_col = [p for p in df.columns.values if \"Avg\" in p]\n",
    "    hour_col = [p for p in df_train.columns.values if \"Hour_\" in p]\n",
    "\n",
    "    X = load_col + price_col + windprod_col + weekday + temp_col + solar_col + wind_col + min_col + max_col + avg_col + hour_col\n",
    "       \n",
    "    test_size = 1\n",
    "    Y = ['PriceMWh']\n",
    "    dummies = weekday + hour_col\n",
    "    X_no_dummies = [x for x in X if x not in dummies]\n",
    "\n",
    "    if get_counts:\n",
    "        preds, counts, scores, cv_res = rolling_window_grid(search, df_train, df_test, X, Y, X_no_dummies, train_size=train_size, test_size=test_size, hyp_opt_freq=hyp_opt_freq, get_counts=get_counts)\n",
    "    else:\n",
    "        preds = rolling_window_grid(search, df_train, df_test, X, Y, X_no_dummies, train_size=train_size, test_size=test_size, hyp_opt_freq=hyp_opt_freq, get_counts=get_counts)\n",
    "    \n",
    "    out = [preds.ravel(), df_test[Y].values.ravel()]\n",
    "\n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(out, fp)\n",
    "        \n",
    "    if get_counts:\n",
    "        path1 = 'results\\coef_' + path\n",
    "        with open(path1, 'wb') as fp:\n",
    "            pickle.dump([counts, X], fp)\n",
    "        path2 = r'results\\training_set_' + path\n",
    "        with open(path2, 'wb') as fp:\n",
    "            pickle.dump(scores, fp)\n",
    "        path2 = r'results\\cv_' + path\n",
    "        with open(path2, 'wb') as fp:\n",
    "            pickle.dump(cv_res, fp)\n",
    "        \n",
    "    return preds\n",
    "\n",
    "def LightGBM_nw(search, df_train, df_test, train_size, path, hyp_opt_freq=60):\n",
    "    load_col = [p for p in df.columns.values if \"load\" in p and '_h' in p]\n",
    "    weekday = ['Mon', 'Tue', 'Wen', 'Thur', 'Fri', 'Sat', 'Sun']\n",
    "    windprod_col = [p for p in df.columns.values if \"Wind\" in p in p and '_h' in p]\n",
    "    price_col = [p for p in df.columns.values if \"Price\" in p and p != 'PriceMWh' and '_h' in p]\n",
    "    min_col = [p for p in df.columns.values if \"Min\" in p]\n",
    "    max_col = [p for p in df.columns.values if \"Max\" in p]\n",
    "    avg_col = [p for p in df.columns.values if \"Avg\" in p]\n",
    "    hour_col = [p for p in df_train.columns.values if \"Hour_\" in p]\n",
    "\n",
    "    X = load_col + price_col + windprod_col + weekday + min_col + max_col + avg_col + hour_col\n",
    "    \n",
    "    test_size = 1\n",
    "    Y = ['PriceMWh']\n",
    "    dummies = weekday + hour_col\n",
    "    X_no_dummies = [x for x in X if x not in dummies]\n",
    "    \n",
    "    preds = rolling_window_grid(search, df_train, df_test, X, Y, X_no_dummies, train_size=train_size, test_size=test_size, hyp_opt_freq=hyp_opt_freq)\n",
    "    out = [preds.ravel(), df_test[Y].values.ravel()]\n",
    "\n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(out, fp)\n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMRegressor(\n",
    "                    n_jobs=-1,\n",
    "                    reg_lambda = 0.1, \n",
    "                    reg_alpha= 0.1,\n",
    "                    learning_rate=0.05,\n",
    "                    boosting_type = \"goss\",\n",
    "                    saved_feature_importance_type = 1,\n",
    "                    )\n",
    "\n",
    "mc_cross_val = MonteCarloCV(n_splits=2, \n",
    "                    train_size=0.6, \n",
    "                    test_size=0.1, \n",
    "                    gap=168)\n",
    "\n",
    "parameters = {\n",
    "        'max_depth': [3, 7, 16],\n",
    "        'n_estimators': [500, 1000, 1500, 2000],\n",
    "        'num_leaves': [16, 31, 50],\n",
    "        'min_child_samples': [20, 50, 100, 150]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model_lgbm,\n",
    "    param_grid=parameters,\n",
    "    n_jobs = -1,\n",
    "    cv = mc_cross_val,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMRegressor(\n",
    "                    n_jobs=-1,\n",
    "                    boosting_type = \"goss\",\n",
    "                    saved_feature_importance_type = 1,\n",
    "                    ) #, num_leaves=16, min_child_samples = 35, reg_lambda=0.5, n_estimators=500\n",
    "\n",
    "mc_cross_val = MonteCarloCV(n_splits=4, \n",
    "                    train_size=0.6, \n",
    "                    test_size=0.1, \n",
    "                    gap=168)\n",
    "\n",
    "parameters = {\n",
    "      'learning_rate': (0.0001, 0.1, \"log-uniform\"),\n",
    "      'max_depth': (4,50),\n",
    "      'n_estimators': (100, 2000),\n",
    "      'num_leaves': (8, 50),\n",
    "      'min_child_samples': (20, 200),\n",
    "      'reg_lambda': (0.0001, 1),\n",
    "      'reg_alpha': (1e-5, 0.999,\"log-uniform\"),\n",
    "      'reg_lambda': (1e-5, 0.999,\"log-uniform\"),\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=model_lgbm,\n",
    "    n_iter = 70,\n",
    "    search_spaces=parameters,\n",
    "    n_jobs = -1,\n",
    "    cv = mc_cross_val,\n",
    "    verbose=0,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data\n",
    "np.int = np.int_\n",
    "test_start = [2019,7,1]\n",
    "test_end = [2021,7,1]\n",
    "df_train, df_test = get_train_test(df, start=test_start, end=test_end)\n",
    "train_size = 365*3\n",
    "preds = LightGBM_all(bayes_search, df_train, df_test, train_size, 'results\\lightGBMallbayes_Period1_Year3.txt', get_counts=True, hyp_opt_freq=183)\n",
    "\n",
    "Y = [\"PriceMWh\"]\n",
    "plt.plot(range(len(df_test[Y])), df_test[Y])\n",
    "plt.plot(range(len(preds)), preds)\n",
    "plt.show()\n",
    "\n",
    "print('MAE', MAE(y_true = df_test[Y], y_pred = preds))\n",
    "print('MSE', MSE(y_true = df_test[Y], y_pred =  preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no weather data\n",
    "test_start = [2019,7,1]\n",
    "test_end = [2021,7,1]\n",
    "df_train, df_test = get_train_test(df, start=test_start, end=test_end)\n",
    "train_size = 365*3\n",
    "preds = LightGBM_nw(bayes_search, df_train, df_test, train_size, 'results\\lightGBMnwbayes_Period1_Year3.txt', hyp_opt_freq=183)\n",
    "\n",
    "Y = [\"PriceMWh\"]\n",
    "plt.plot(range(len(df_test[Y])), df_test[Y])\n",
    "plt.plot(range(len(preds)), preds)\n",
    "plt.show()\n",
    "\n",
    "print('MAE', MAE(y_true = df_test[Y], y_pred = preds))\n",
    "print('MSE', MSE(y_true = df_test[Y], y_pred =  preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periode 2: 2021, 2022\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "test_start = [2021,1,1]\n",
    "test_end = [2023,1,1]\n",
    "df_train, df_test = get_train_test(df, start=test_start, end=test_end)\n",
    "train_size = 365*3\n",
    "preds = LightGBM_all(bayes_search, df_train, df_test, train_size, 'results\\lightGBMallbayes_Period2_Year3.txt', get_counts=True, hyp_opt_freq=183)\n",
    "\n",
    "Y = [\"PriceMWh\"]\n",
    "plt.plot(range(len(df_test[Y])), df_test[Y])\n",
    "plt.plot(range(len(preds)), preds)\n",
    "plt.show()\n",
    "\n",
    "print('MAE', MAE(y_true = df_test[Y], y_pred = preds))\n",
    "print('MSE', MSE(y_true = df_test[Y], y_pred =  preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no weather data\n",
    "test_start = [2021,1,1]\n",
    "test_end = [2023,1,1]\n",
    "df_train, df_test = get_train_test(df, start=test_start, end=test_end)\n",
    "train_size = 365*3\n",
    "preds = LightGBM_nw(bayes_search, df_train, df_test, train_size, 'results\\lightGBMnwbayes_Period2_Year3.txt', hyp_opt_freq=183)\n",
    "\n",
    "Y = [\"PriceMWh\"]\n",
    "plt.plot(range(len(df_test[Y])), df_test[Y])\n",
    "plt.plot(range(len(preds)), preds)\n",
    "plt.show()\n",
    "\n",
    "print('MAE', MAE(y_true = df_test[Y], y_pred = preds))\n",
    "print('MSE', MSE(y_true = df_test[Y], y_pred =  preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
